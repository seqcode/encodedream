# Cross cell-type transcription factor binding prediction using deep learning models
Guanjue Xiang, Akshay Kakumanu, Divyanshi Srivastava, Naomi Yamada, Lila Rieber and Shaun Mahony

## Background:
We used two very different approaches to tackle the “ENCODE-DREAM” challenge. Our first approach relies on the assumption that TF binding in a given cell type is determined by an unknown mixture of two types of genomic features: 1) features that represent invariant properties of the TF itself; and 2) features that represent cell-specific interactions with other regulatory actors. We used this approach to make submissions for the conference round of the challenge. While working on the conference round, we realized that finding cell-type specific features de novo using DNase-Seq and RNA-Seq datasets turned out to be harder than we anticipated. This resulted in the poor performance of our overall model. On closer examination of the challenge datasets, we realized that for a majority of cases the test cell-type was closely related to one of the train cell-type. This motivated us to try our second approach. Instead of training on all the cell-types, we reasoned that training an extensive deep learning model on the closest related cell-type would be more effective. Briefly, our model has two convolutional layers that feed-forward to an LSTM layer, which is in turn connected to a two class out-put layer (Figure 1). The novelty of our approach lies in the way we incorporated a DNase-tag count based scaling of the output of the first convolutional layer. Details of both the approaches can be found in the following section. 

## Methods:
### Frist approach (Conference round):
We aim to take a transfer learning approach to the challenge. We first train three separate types of classifiers to recognize: 1) the primary binding motif of the TF of interest; 2) properties of TF binding sites that are bound in all training cell types; and 3) general cell-specific motif features associated with accessible regions in each training and test cell type. A fourth classifier is trained to integrate the outputs of each of the three preceding classifiers along with other genomic features (DNase tag counts and distance to TSS) to predict bound/unbound labels. The parameters of this final classifier are trained using the training datasets and then directly applied (i.e. transferred) to make predictions in the test cell type(s). The underlying idea is that we train the final classifier to recognize how important the various invariant and cell-specific features are in determining binding sites in the training cell types, and then these general parameters are assumed to also apply to the test cell type(s).

#### General training data definitions:
Definition of accessible regions from DNase-seq data: We used a custom domain finder ("SEED") to call DNase-seq-enriched domains for each cell type. Our domain-finder used a sliding window of 200bp (100bp step), a Poisson threshold of p<10^-5, and a Binomial test threshold of p<0.05 to call enriched regions. Normalized DNase tag count features: For each cell type, we counted DNase-seq tags in 600bp windows around all test coordinates along the genome. Tag counts are normalized using total tag counts. 600bp was chosen as the window size as it gave the best naive discrimination between bound and unbound labels (AUROC). Distances to TSS: Distances between a site and annotated TSSs were calculated using the GENCODE (v19) release.

####Classifier C1: Primary TF binding motif features
The purpose of this classifier is to represent the inherent binding preference of the TF of interest. We train a L1-regularized logistic classifier using counts of a restricted set of wildcard k-mers (8-mers with 2 wildcard positions) in 200bp windows to classify bound/unbound labels in the training cell types. The restricted set of k-mers are chosen to represent top-scoring 8-mers in PBM data for the TF of interest (using data downloaded from the cis-bp database). If no PBM data exists, we generate k-mers from appropriate PWM models for the TF of interest. Since we assume that the TF's binding preference is invariant, only one C1 classifier is trained per TF.

####Classifier C2: Features of shared sites
The purpose of this classifier is to recognize general features of TF binding sites that we expect to be bound in many/all cell types. We first extract "shared" TF binding peaks that are present in all training cell types. We further restrict to shared sites that are accessible in the test cell type. We then train a L1-regularized logistic classifier using 4-mers, 5-mers and 6-mers (excluding k-mers that are substrings of features used to train C1) counts within 200bp windows using the shared sites as the positive set and unbound sequences 500bp away as the negative set. We train one C2 classifier for each training and test cell type (since the accessibility filter can change the training set in each cell type).

####Classifier C3: Cell-specific motif features
The purpose of this classifier is to recognize features associated with distal accessible regions of chromatin in each cell type. Beginning with our defined DNase-seq-enriched domains for a given cell type, we filter out domains that are within 10Kbp of an annotated TSS. We then rank these distal domains by scores obtained by scanning the C1 classifier. We then train a L1-regularized logistic classifier using 4-mers, 5-mers and 6-mers (excluding k-mers that are substrings of features used to train C1) counts within 200bp windows using the top ranked distal accessible regions as the positive set and random regions as the negative set. We train one C3 classifier for each training and test cell type.

####Final classifier: Predicting Bound/Unbound labels
This classifier takes the following as input features for each test coordinate along the genome: 
 - C1 classifier score (representing primary motif features)
 - C2 classifier score (representing features of shared sites)
 - C3 classifier score (representing cell-specific motifs)
 - Normalized DNase-seq tag counts
 - Distance to TSS
We train a random forest classifier using these features to predict observed Bound/Unbound labels in each training cell type. Input features (other than the C1 score and distance to TSS) are defined using cell-type appropriate sources for each training example. The trained random forest classifier is used to make predictions on Bound/Unbound labels along the genome for the test cell type(s), where we again substitute cell-type appropriate sources of input features for the C2, C3, and DNase tag count scores. 

### Second approach (Conference round):
Data processing: Deep learning models have been shown to learn complex sequence grammars (Schmidhuber, et al., 2015; Sak, et al., 2014; Alipanahi, et al.,2015; Kelley, et al., 2016). Hence, in-order to learn a single transferable model, we restricted our training cell-types to ones that closely match the test cell-type. Further, we made predictions at only those sites that are DNase accessible in the test cell-type. We realize that this is a very strong assumption and might not hold well for factors that bind as huge complexes and hence are more likely to be bound in regions that are not DNase accessible. However, we stick to this assumption as it holds fairly well for a majority of the factors in this challenge. Overall, our network has two convolutional layers, one long-short-term-memory (LSTM) layer and one fully connected layer. The intuition behind these design choices is as follows:
•	The first convolutional layers servers as a di-mer scanner. We used 15 filters for the first layer (each of size 2).
•	The output of the first layer is scaled using the 200bp DNase tag-counts. We believe that doing this further incorporates the cell-type specific DNase accessibility information.
•	For the second convolutional layer, we use 15 filters of size 8. We hope that this choice of architectural design would capture higher order grammars among regulatory elements.
•	Since our input data is unaligned, we use an LSTM layer to account for that. LSTM layers have shown a lot of potential in dealing with un-aligned sequences (Sak, et al., 2014).
In order to deal with the highly imbalanced nature of the datasets, we use the following mini-batch approach. We randomly select 200 positive and an equal number of negative data instances for every step in the training process.

##Outcome & future directions
We do not expect that the current version of our approach is performing well on the challenge data, as we did not have sufficient time to optimize and extend the component classifiers. However, we plan to continue working on this challenge for the January deadline. Future directions for improving the model will focus on changing the form and complexity of each of the component classifiers. 


## Discussion/Suggestions for improving the challenge:
Firstly, we'd like to congratulate the organizers for putting together this timely challenge. Challenges like this not only allow us to assess the state of the art within a particular application domain, they also have a lasting impact on the direction of future computational biology research. Bearing this in mind, it may be useful for the organizers to justify or discuss some of the following challenge design choices in the planned manuscript describing the challenge results: 1) The challenge itself is framed as predicting TF binding, when in fact it asks us to predict the outcome of a peak-finder when run on ChIP-seq data. This distinction matters when we consider the exact nature of the requested predictions: we are asked to predict binary labels for 200bp segments over a relatively wide window around binding events. The window of consecutive "B" (bound) labels around predicted binding peaks is relatively large (often 800bp+) compared with the biological TF-DNA binding event. In practice, then, most of the "B" labeled 200bp segments do not in fact contain the TF-bound DNA bases. This makes the challenge exceedingly difficult; we could in theory train a highly specific model that would perfectly predict which 200bp sequences are bound by a TF, but this model would still not correctly predict most of the "B" labels in the challenge. 2) It would have been useful for some approaches to have access to the raw ChIP-seq signals for training instead of peak calls. 3) This challenge focuses on predicting TF binding between cell types, which may lead some to assume that the complementary within cell type TF binding challenge has been solved (i.e. training on ChIP-seq and DNase-seq for a subset of chromosomes and predicting TF binding in the other chromosomes). It's not obvious that this is true, and directly testing the ability of current approaches to solve this within-cell problem would serve as a useful baseline.
 

##Provided code
We have provided a code repository containing all of our code and scripts for this project. An example run-through of our procedure is provided in scripts/run.sh in this repo. Note that this shell script is for illustration only. We have not tested that the script runs for a new dataset off of our local computing environment. If this is necessary, we are happy to debug and modify the codes to run on your systems. Please contact Shaun (mahony@psu.edu) or Akshay (auk262@psu.edu) or Guanjue (gzx103@psu.edu). 

[Figure 1]: https://github.com/seqcode/encodedream/blob/master/lstmscripts/lstm.png


